---
title: "Introduction to mr.mash"
author: Peter Carbonetto & Fabio Morgante
date: "`r Sys.Date()`"
output:
  html_document:
    toc: no
    toc_float: no
    highlight: textmate
    theme: readable
vignette: >
  %\VignetteIndexEntry{Introduction to mr.mash}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

The aim of this vignette is to introduce the basic steps of a
*mr.mash* analysis through a toy example. 

```{r knitr-opts, include=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,results = "hold",
                      fig.align = "center",dpi = 120)
```

First, we set the seed and load the `mr.mash.alpha` R package.

```{r set-seed}
library(mr.mash.alpha)
set.seed(123)
```

## Step 1 -- Simulate example data

We start by simulating a data set with 800 individuals, 1000
predictors and 5 responses.  We then 5 causal variables (randomly
sampled from the total 1000) are assigned equal effects across
responses and explain 20\% of the total per-response variance. This
would be roughly equivalent to one gene in the "equal effects"
scenario in the *mr.mash* (with the difference being that genotypes
are simulated here).

```{r sim-data-1, results="hide"}
n <- 300
p <- 1000
p_causal <- 5
r <- 5
pve <- 0.2
B_cor <- 1
out <- simulate_mr_mash_data(n, p, p_causal, r, pve=pve, B_cor=B_cor,
                             B_scale=1, X_cor=0, X_scale=1, V_cor=0)
```

## Step 2 -- Split the data into training and test sets

We then split the data into a training set and a test set.

```{r sim-data-2}
ntest <- 200
Ytrain <- out$Y[-(1:ntest),]
Xtrain <- out$X[-(1:ntest),]
Ytest <- out$Y[1:ntest,]
Xtest <- out$X[1:ntest,]
```

## Step 3 -- Define the mixture prior

To run *mr.mash*, we need to first specify the covariances in the
mixture-of-normals prior, which are supposed to capture the effect 
sharing patterns across responses. In this example, we use a mixture of
"canonical" covariances computed using `compute_canonical_covs()`. 
However, "data-driven" covariances can also be used -- here's an
[example](https://stephenslab.github.io/mashr/articles/intro_mash_dd.html)
of how to compute these matrices. 
Regardless of the type of covariance matrices, these are each multiplied 
by a grid of scaling factors computed using `autoselect.mixsd()`, which 
are supposed to capture the magnitude of the effects. The expansion is done
using `expand_covs()`, which also adds a matrix of all zeros (our spike) 
when requested. The grid is derived from the regression coefficients and 
their standard errors from univariate simple linear regression which can be
computed using `compute_univariate_sumstats()`.

```{r specify-prior}
univ_sumstats <- compute_univariate_sumstats(Xtrain, Ytrain,
                   standardize=TRUE, standardize.response=FALSE)
grid <- autoselect.mixsd(univ_sumstats, mult=sqrt(2))^2
S0 <- compute_canonical_covs(ncol(Ytrain), singletons=TRUE,
                             hetgrid=c(0, 0.25, 0.5, 0.75, 1))
S0 <- expand_covs(S0, grid, zeromat=TRUE)
```

## Step 4 -- Fit *mr.mash* to the training data

Now we are ready to fit a mr.mash model to the training data using `mr.mash()`,
to estimate the posterior mean of the regression coefficients.

```{r fit-mr-mash, results="hide"}
S0_ind <- compute_canonical_covs(ncol(Ytrain),singletons = FALSE,
                                 hetgrid = c(0,0.001,0.01))
S0_ind <- expand_covs(S0_ind,grid,zeromat = TRUE)
fit_ind <- mr.mash(Xtrain,Ytrain,S0_ind,update_V = TRUE)
fit <- mr.mash(Xtrain,Ytrain,S0,update_V = TRUE)
par(mfrow = c(1,2))
plot(out$B,fit_ind$mu1,pch = 20,xlim = c(-1.75,0.75),ylim = c(-1.75,0.75),
     main = cor(as.vector(out$B),as.vector(fit_ind$mu1)))
abline(a = 0,b = 1,col = "royalblue",lty = "dotted")
plot(out$B,fit$mu1,pch = 20,xlim = c(-1.75,0.75),ylim = c(-1.75,0.75),
     main = cor(as.vector(out$B),as.vector(fit$mu1)))
abline(a = 0,b = 1,col = "royalblue",lty = "dotted")
```

## Step 5 -- Predict responses in the test
We then use the fitted model from step 4 to predict the response values in the 
test set. In this plot, we compare the true and predicted values

```{r plot-pred-test, fig.height=5, fig.width=5}
Ytest_est <- predict(fit,Xtest)
plot(Ytest_est,Ytest,pch = 20,col = "darkblue",xlab = "true",
     ylab = "predicted")
abline(a = 0,b = 1,col = "magenta",lty = "dotted")
```

However, we also want to assess prediction accuracy more
formally. Here, we do that in terms of $R^2$ which is easy to
interpret -- its maximum value would be the proportion of variance
explained, 0.2 in this case).

```{r pred-acc-test}
r2 <- vector("numeric", r)
for(i in 1:r){
  fit_acc  <- lm(Ytest[, i] ~ Ytest_est[, i])
  r2[i] <- summary(fit_acc)$r.squared
}

r2
```

We can see that the predictions are pretty accurate.

